{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmartins\\anaconda3\\envs\\mmSNN\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import snntorch as snn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from snntorch import utils\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from snntorch import spikegen\n",
    "import numpy as np\n",
    "\n",
    "dtype = torch.float\n",
    "torch.set_default_dtype(dtype)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 129, 81) (2100,) (900, 129, 81) (900,)\n"
     ]
    }
   ],
   "source": [
    "audio_stim = np.load('auditory_stimuli.npz')\n",
    "X_train_raw = audio_stim['X_train']\n",
    "X_test_raw = audio_stim['X_test']\n",
    "y_train = audio_stim['y_train']\n",
    "y_test = audio_stim['y_test']\n",
    "\n",
    "print(X_train_raw.shape, y_train.shape, X_test_raw.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.zeros([\n",
    "    np.size(X_train_raw,0),\n",
    "    np.size(X_train_raw,1) * np.size(X_train_raw,2)\n",
    "])\n",
    "X_test = np.zeros([\n",
    "    np.size(X_test_raw,0),\n",
    "    np.size(X_test_raw,1) * np.size(X_test_raw,2)\n",
    "])\n",
    "\n",
    "for i in range(np.size(X_train_raw,0)):\n",
    "    X_train[i,:] = np.ravel(X_train_raw[i,:,:])\n",
    "\n",
    "for i in range(np.size(X_test_raw,0)):\n",
    "    X_test[i,:] = np.ravel(X_test_raw[i,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader arguments\n",
    "batch_size = 128*4\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_train.astype(np.float32)),\n",
    "    torch.from_numpy(y_train.astype(np.float32))\n",
    ")\n",
    "testing_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_test.astype(np.float32)),\n",
    "    torch.from_numpy(y_test.astype(np.float32))\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 30\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Define Network\n",
    "class AudNet(nn.Module):\n",
    "    def __init__(self,\n",
    "        num_inputs=None, num_hidden=1000, num_last_hidden=20, num_output=10,\n",
    "        beta=0.95, num_steps=81, num_freq=129):\n",
    "        super().__init__()\n",
    "\n",
    "        if num_inputs is None:\n",
    "            num_inputs = num_freq\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.num_freq = num_freq\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        self.fc3 = nn.Linear(num_hidden, num_last_hidden)\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "        self.fc4 = nn.Linear(num_last_hidden, num_output)\n",
    "        self.lif4 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x.to(torch.float32)\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif3.init_leaky()\n",
    "\n",
    "        output_spike_record = []\n",
    "        output_memV_record = []\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "\n",
    "            x_ = x.reshape(-1, self.num_freq, self.num_steps)[:,:,step]\n",
    "\n",
    "            cur1 = self.fc1(x_)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "            cur4 = self.fc4(spk3)\n",
    "            spk4, mem4 = self.lif4(cur4, mem4)\n",
    "\n",
    "            output_spike_record.append(spk4)\n",
    "            output_memV_record.append(mem4)\n",
    "\n",
    "        self.mem1.append(torch.stack(mem1))\n",
    "        self.mem2.append(torch.stack(mem2))\n",
    "        self.mem3.append(torch.stack(mem3))\n",
    "\n",
    "        return  torch.stack(output_spike_record, dim=0), torch.stack(output_memV_record, dim=0)\n",
    "\n",
    "    def fwd_frozen(self, x):\n",
    "\n",
    "        mem1 = self.mem1\n",
    "        mem2 = self.mem2\n",
    "        mem3 = self.mem3\n",
    "\n",
    "        last_hidden_spike_record = []\n",
    "        last_hidden_output_memV_record = []\n",
    "\n",
    "        for step in range(self.num_steps):\n",
    "\n",
    "            x_ = x.reshape(self.num_freq, self.num_steps)[:,step]\n",
    "\n",
    "            cur1 = self.fc1(x_)\n",
    "            spk1, mem1 = self.lif1(cur1, mem1)\n",
    "\n",
    "            cur2 = self.fc2(spk1)\n",
    "            spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "            cur3 = self.fc3(spk2)\n",
    "            spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "            last_hidden_spike_record.append(spk3)\n",
    "            last_hidden_output_memV_record.append(mem3)\n",
    "\n",
    "        return torch.stack(last_hidden_spike_record, dim=0), torch.stack(last_hidden_output_memV_record, dim=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_sz = np.size(X_train, 1)\n",
    "# Load the network onto CUDA if available\n",
    "net = AudNet().to(device)\n",
    "\n",
    "# pass data into the network, sum the spikes over time\n",
    "# and compare the neuron with the highest number of spikes\n",
    "# with the target\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data.view(batch_size, -1))\n",
    "    _, idx = output.max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    # if train:\n",
    "    #     print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    # else:\n",
    "    print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}, Train loss = {loss_hist[counter]:.2f} Test loss = {test_loss_hist[counter]:.2f} \\n\")\n",
    "    print_batch_accuracy(data, targets)\n",
    "    print('\\n')\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        # loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        loss_val = loss(mem_rec, targets.type(torch.long))\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
    "\n",
    "            # Test set loss\n",
    "            # test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            # for step in range(num_steps):\n",
    "            test_loss = loss(test_mem, test_targets.type(torch.long))\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 50 == 0:\n",
    "                train_printer()\n",
    "            counter += 1\n",
    "            iter_counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 10449])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.view(batch_size, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 10449])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.view(batch_size, -1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10449"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "129*81"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _ = net(data.view(batch_size, -1))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = output.max(1)\n",
    "# acc = np.mean((targets == idx).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mem.shape, test_targets.type(torch.long).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, s = spectrogram(X_train[2,:], fs=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[0,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(s)\n",
    "plt.xlim([0,20])\n",
    "plt.ylim([0,20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(X_train[1,:], 'k')\n",
    "plt.xlim([0,2400])\n",
    "plt.xlabel('samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "spk_rec.shape, mem_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmSNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
