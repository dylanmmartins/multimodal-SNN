{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dmartins\\anaconda3\\envs\\mmSNN\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import snntorch as snn\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from snntorch import utils\n",
    "\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from snntorch import spikegen\n",
    "import numpy as np\n",
    "\n",
    "dtype = torch.float\n",
    "torch.set_default_dtype(dtype)\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_stim = np.load('auditory_stimuli.npz')\n",
    "X_train = audio_stim['X_train']\n",
    "X_test = audio_stim['X_test']\n",
    "y_train = audio_stim['y_train']\n",
    "y_test = audio_stim['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataloader arguments\n",
    "batch_size = 128*2\n",
    "\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "training_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_train.astype(np.float32)),\n",
    "    torch.from_numpy(y_train.astype(np.float32))\n",
    ")\n",
    "testing_dataset = TensorDataset(\n",
    "    torch.from_numpy(X_test.astype(np.float32)),\n",
    "    torch.from_numpy(y_test.astype(np.float32))\n",
    ")\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(training_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "test_loader = DataLoader(testing_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Iteration 0, Train loss = 8.01 Test loss = 7.83 \n",
      "\n",
      "Test set accuracy for a single minibatch: 7.42%\n",
      "\n",
      "\n",
      "Epoch 1, Iteration 2, Train loss = 2.33 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 10.16%\n",
      "\n",
      "\n",
      "Epoch 2, Iteration 4, Train loss = 2.31 Test loss = 2.30 \n",
      "\n",
      "Test set accuracy for a single minibatch: 8.98%\n",
      "\n",
      "\n",
      "Epoch 3, Iteration 6, Train loss = 2.31 Test loss = 2.31 \n",
      "\n",
      "Test set accuracy for a single minibatch: 7.81%\n",
      "\n",
      "\n",
      "Epoch 5, Iteration 0, Train loss = 2.31 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 9.77%\n",
      "\n",
      "\n",
      "Epoch 6, Iteration 2, Train loss = 2.32 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 9.77%\n",
      "\n",
      "\n",
      "Epoch 7, Iteration 4, Train loss = 2.30 Test loss = 2.31 \n",
      "\n",
      "Test set accuracy for a single minibatch: 9.77%\n",
      "\n",
      "\n",
      "Epoch 8, Iteration 6, Train loss = 2.33 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 12.11%\n",
      "\n",
      "\n",
      "Epoch 10, Iteration 0, Train loss = 2.30 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 10.16%\n",
      "\n",
      "\n",
      "Epoch 11, Iteration 2, Train loss = 2.32 Test loss = 2.31 \n",
      "\n",
      "Test set accuracy for a single minibatch: 7.42%\n",
      "\n",
      "\n",
      "Epoch 12, Iteration 4, Train loss = 2.33 Test loss = 2.31 \n",
      "\n",
      "Test set accuracy for a single minibatch: 11.72%\n",
      "\n",
      "\n",
      "Epoch 13, Iteration 6, Train loss = 2.32 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 9.38%\n",
      "\n",
      "\n",
      "Epoch 15, Iteration 0, Train loss = 2.32 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 7.42%\n",
      "\n",
      "\n",
      "Epoch 16, Iteration 2, Train loss = 2.31 Test loss = 2.33 \n",
      "\n",
      "Test set accuracy for a single minibatch: 10.16%\n",
      "\n",
      "\n",
      "Epoch 17, Iteration 4, Train loss = 2.30 Test loss = 2.31 \n",
      "\n",
      "Test set accuracy for a single minibatch: 5.47%\n",
      "\n",
      "\n",
      "Epoch 18, Iteration 6, Train loss = 2.33 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 11.33%\n",
      "\n",
      "\n",
      "Epoch 20, Iteration 0, Train loss = 2.31 Test loss = 2.34 \n",
      "\n",
      "Test set accuracy for a single minibatch: 8.59%\n",
      "\n",
      "\n",
      "Epoch 21, Iteration 2, Train loss = 2.33 Test loss = 2.33 \n",
      "\n",
      "Test set accuracy for a single minibatch: 10.94%\n",
      "\n",
      "\n",
      "Epoch 22, Iteration 4, Train loss = 2.31 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 8.20%\n",
      "\n",
      "\n",
      "Epoch 23, Iteration 6, Train loss = 2.34 Test loss = 2.32 \n",
      "\n",
      "Test set accuracy for a single minibatch: 8.59%\n",
      "\n",
      "\n",
      "Epoch 25, Iteration 0, Train loss = 2.34 Test loss = 2.33 \n",
      "\n",
      "Test set accuracy for a single minibatch: 10.16%\n",
      "\n",
      "\n",
      "Epoch 26, Iteration 2, Train loss = 2.33 Test loss = 2.30 \n",
      "\n",
      "Test set accuracy for a single minibatch: 10.55%\n",
      "\n",
      "\n",
      "Epoch 27, Iteration 4, Train loss = 2.33 Test loss = 2.31 \n",
      "\n",
      "Test set accuracy for a single minibatch: 7.81%\n",
      "\n",
      "\n",
      "Epoch 28, Iteration 6, Train loss = 2.31 Test loss = 2.33 \n",
      "\n",
      "Test set accuracy for a single minibatch: 9.38%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Network Architecture\n",
    "num_hidden = 3000\n",
    "num_outputs = 100\n",
    "\n",
    "num_epochs = 30\n",
    "loss_hist = []\n",
    "test_loss_hist = []\n",
    "counter = 0\n",
    "\n",
    "# Temporal Dynamics\n",
    "beta = 0.95\n",
    "\n",
    "# Define Network\n",
    "class AudNet(nn.Module):\n",
    "    def __init__(self, num_inputs):\n",
    "        super().__init__()\n",
    "\n",
    "        # Initialize layers\n",
    "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.lif1 = snn.Leaky(beta=beta)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif2 = snn.Leaky(beta=beta)\n",
    "        self.fc3 = nn.Linear(num_hidden, num_hidden)\n",
    "        self.lif3 = snn.Leaky(beta=beta)\n",
    "        self.fc4 = nn.Linear(num_hidden, num_outputs)\n",
    "        self.lif4 = snn.Leaky(beta=beta)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x.to(torch.float32)\n",
    "\n",
    "        # Initialize hidden states at t=0\n",
    "        mem1 = self.lif1.init_leaky()\n",
    "        mem2 = self.lif2.init_leaky()\n",
    "        mem3 = self.lif3.init_leaky()\n",
    "        mem4 = self.lif3.init_leaky()\n",
    "\n",
    "        cur1 = self.fc1(x)\n",
    "        spk1, mem1 = self.lif1(cur1, mem1)\n",
    "\n",
    "        cur2 = self.fc2(spk1)\n",
    "        spk2, mem2 = self.lif2(cur2, mem2)\n",
    "\n",
    "        cur3 = self.fc3(spk2)\n",
    "        spk3, mem3 = self.lif3(cur3, mem3)\n",
    "\n",
    "        cur4 = self.fc3(spk3)\n",
    "        spk4, mem4 = self.lif3(cur3, mem4)\n",
    "\n",
    "        return  spk4, mem4\n",
    "\n",
    "# Load the network onto CUDA if available\n",
    "net = AudNet(num_inputs=np.size(X_train,1)).to(device)\n",
    "\n",
    "# pass data into the network, sum the spikes over time\n",
    "# and compare the neuron with the highest number of spikes\n",
    "# with the target\n",
    "\n",
    "def print_batch_accuracy(data, targets, train=False):\n",
    "    output, _ = net(data.view(batch_size, -1))\n",
    "    _, idx = output.max(1)\n",
    "    acc = np.mean((targets == idx).detach().cpu().numpy())\n",
    "\n",
    "    # if train:\n",
    "    #     print(f\"Train set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "    # else:\n",
    "    print(f\"Test set accuracy for a single minibatch: {acc*100:.2f}%\")\n",
    "\n",
    "def train_printer():\n",
    "    print(f\"Epoch {epoch}, Iteration {iter_counter}, Train loss = {loss_hist[counter]:.2f} Test loss = {test_loss_hist[counter]:.2f} \\n\")\n",
    "    print_batch_accuracy(data, targets)\n",
    "    print('\\n')\n",
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=5e-4, betas=(0.9, 0.999))\n",
    "\n",
    "\n",
    "# Outer training loop\n",
    "for epoch in range(num_epochs):\n",
    "    iter_counter = 0\n",
    "    train_batch = iter(train_loader)\n",
    "\n",
    "    # Minibatch training loop\n",
    "    for data, targets in train_batch:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # forward pass\n",
    "        net.train()\n",
    "        spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "\n",
    "        # initialize the loss & sum over time\n",
    "        # loss_val = torch.zeros((1), dtype=dtype, device=device)\n",
    "        loss_val = loss(mem_rec, targets.type(torch.long))\n",
    "\n",
    "        # Gradient calculation + weight update\n",
    "        optimizer.zero_grad()\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Store loss history for future plotting\n",
    "        loss_hist.append(loss_val.item())\n",
    "\n",
    "        # Test set\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            test_data, test_targets = next(iter(test_loader))\n",
    "            test_data = test_data.to(device)\n",
    "            test_targets = test_targets.to(device)\n",
    "\n",
    "            # Test set forward pass\n",
    "            test_spk, test_mem = net(test_data.view(batch_size, -1))\n",
    "\n",
    "            # Test set loss\n",
    "            # test_loss = torch.zeros((1), dtype=dtype, device=device)\n",
    "            # for step in range(num_steps):\n",
    "            test_loss = loss(test_mem, test_targets.type(torch.long))\n",
    "            test_loss_hist.append(test_loss.item())\n",
    "\n",
    "            # Print train/test loss/accuracy\n",
    "            if counter % 10 == 0:\n",
    "                train_printer()\n",
    "            counter += 1\n",
    "            iter_counter +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _ = net(data.view(batch_size, -1))\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, idx = output.max(1)\n",
    "# acc = np.mean((targets == idx).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mem.shape, test_targets.type(torch.long).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mem.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spk_rec, mem_rec = net(data.view(batch_size, -1))\n",
    "spk_rec.shape, mem_rec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in net.parameters():\n",
    "    print(param.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mmSNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
