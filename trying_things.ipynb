{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import snntorch as snn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Michael's idea -- simple, symbolic position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(pos, dim=5, noise=False):\n",
    "    vision_pos = np.zeros(dim)\n",
    "    vision_pos[pos] = 1\n",
    "\n",
    "    audio_pos = np.zeros(dim)\n",
    "    audio_pos[pos] = 1\n",
    "\n",
    "    true_pos = np.zeros(dim)\n",
    "    true_pos[pos] = 1\n",
    "\n",
    "    return vision_pos, audio_pos, true_pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mnist but spike encoding \n",
    "https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_1.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "https://snntorch.readthedocs.io/en/latest/tutorials/tutorial_3.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import snntorch as snn\n",
    "from snntorch import spikeplot as splt\n",
    "from snntorch import spikegen\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def leaky_integrate_and_fire(mem, x, w, beta, threshold=1):\n",
    "  spk = (mem > threshold) # if membrane exceeds threshold, spk=1, else, 0\n",
    "  mem = beta * mem + w*x - spk*threshold\n",
    "  return spk, mem\n",
    "\n",
    "# set neuronal parameters\n",
    "delta_t = torch.tensor(1e-3)\n",
    "tau = torch.tensor(5e-3)\n",
    "beta = torch.exp(-delta_t/tau)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_steps = 200\n",
    "\n",
    "# initialize inputs/outputs + small step current input\n",
    "x = torch.cat((torch.zeros(10), torch.ones(190)*0.5), 0)\n",
    "mem = torch.zeros(1)\n",
    "spk_out = torch.zeros(1)\n",
    "mem_rec = []\n",
    "spk_rec = []\n",
    "\n",
    "# neuron parameters\n",
    "w = 0.4\n",
    "beta = 0.819\n",
    "\n",
    "# neuron simulation\n",
    "for step in range(num_steps):\n",
    "  spk, mem = leaky_integrate_and_fire(mem, x[step], w=w, beta=beta)\n",
    "  mem_rec.append(mem)\n",
    "  spk_rec.append(spk)\n",
    "\n",
    "# convert lists to tensors\n",
    "mem_rec = torch.stack(mem_rec)\n",
    "spk_rec = torch.stack(spk_rec)\n",
    "\n",
    "plot_cur_mem_spk(x*w, mem_rec, spk_rec, thr_line=1,ylim_max1=0.5,\n",
    "                 title=\"LIF Neuron Model With Weighted Step Voltage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Inputs\n",
    "    - cur_in: each element of W x X[t] is sequentially passed as an input\n",
    "    - mem: the previous step membrane potential, U[t-1], is also passed as input.\n",
    "\n",
    "Outputs\n",
    "    - spk_out: output spike S[t] (‘1’ if there is a spike; ‘0’ if there is no spike)\n",
    "    - mem: membrane potential U[t] of the present step\n",
    "\"\"\"\n",
    "lif1 = snn.Leaky(beta=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small step current input\n",
    "w=0.21\n",
    "cur_in = torch.cat((torch.zeros(10), torch.ones(190)*w), 0)\n",
    "mem = torch.zeros(1)\n",
    "spk = torch.zeros(1)\n",
    "mem_rec = []\n",
    "spk_rec = []\n",
    "\n",
    "# neuron simulation\n",
    "for step in range(num_steps):\n",
    "  spk, mem = lif1(cur_in[step], mem)\n",
    "  mem_rec.append(mem)\n",
    "  spk_rec.append(spk)\n",
    "\n",
    "# convert lists to tensors\n",
    "mem_rec = torch.stack(mem_rec)\n",
    "spk_rec = torch.stack(spk_rec)\n",
    "\n",
    "plot_cur_mem_spk(cur_in, mem_rec, spk_rec, thr_line=1, ylim_max1=0.5,\n",
    "                 title=\"snn.Leaky Neuron Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer parameters\n",
    "num_inputs = 784\n",
    "num_hidden = 1000\n",
    "num_outputs = 10\n",
    "beta = 0.99\n",
    "\n",
    "# initialize layers\n",
    "fc1 = nn.Linear(num_inputs, num_hidden)\n",
    "lif1 = snn.Leaky(beta=beta)\n",
    "fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "lif2 = snn.Leaky(beta=beta)\n",
    "\n",
    "# Initialize hidden states\n",
    "mem1 = lif1.init_leaky()\n",
    "mem2 = lif2.init_leaky()\n",
    "\n",
    "# record outputs\n",
    "mem2_rec = []\n",
    "spk1_rec = []\n",
    "spk2_rec = []\n",
    "\n",
    "spk_in = spikegen.rate_conv(torch.rand((200, 784))).unsqueeze(1)\n",
    "print(f\"Dimensions of spk_in: {spk_in.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network simulation\n",
    "for step in range(num_steps):\n",
    "    cur1 = fc1(spk_in[step]) # post-synaptic current <-- spk_in x weight\n",
    "    spk1, mem1 = lif1(cur1, mem1) # mem[t+1] <--post-syn current + decayed membrane\n",
    "    cur2 = fc2(spk1)\n",
    "    spk2, mem2 = lif2(cur2, mem2)\n",
    "\n",
    "    mem2_rec.append(mem2)\n",
    "    spk1_rec.append(spk1)\n",
    "    spk2_rec.append(spk2)\n",
    "\n",
    "# convert lists to tensors\n",
    "mem2_rec = torch.stack(mem2_rec)\n",
    "spk1_rec = torch.stack(spk1_rec)\n",
    "spk2_rec = torch.stack(spk2_rec)\n",
    "\n",
    "plot_snn_spikes(spk_in, spk1_rec, spk2_rec, \"Fully Connected Spiking Neural Network\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# network simulation\n",
    "for step in range(num_steps):\n",
    "    cur1 = fc1(spk_in[step]) # post-synaptic current <-- spk_in x weight\n",
    "    spk1, mem1 = lif1(cur1, mem1) # mem[t+1] <--post-syn current + decayed membrane\n",
    "    cur2 = fc2(spk1)\n",
    "    spk2, mem2 = lif2(cur2, mem2)\n",
    "\n",
    "    mem2_rec.append(mem2)\n",
    "    spk1_rec.append(spk1)\n",
    "    spk2_rec.append(spk2)\n",
    "\n",
    "# convert lists to tensors\n",
    "mem2_rec = torch.stack(mem2_rec)\n",
    "spk1_rec = torch.stack(spk1_rec)\n",
    "spk2_rec = torch.stack(spk2_rec)\n",
    "\n",
    "plot_snn_spikes(spk_in, spk1_rec, spk2_rec, \"Fully Connected Spiking Neural Network\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
